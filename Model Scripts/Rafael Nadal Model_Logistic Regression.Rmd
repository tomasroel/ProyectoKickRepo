---
title: "Regresión Logística - Aplicación en el Tenis"
author: "Tomás Roel"
date: "July 12, 2021"
output:
  html_document:
    df_print: paged
  html_notebook:
    theme: paper
---

<style>
body {
text-align: justify}
</style>

# Introducción

En la previa de un partido de tenis importante para nuestro tenista favorito, o también en la de un partido de fútbol del equipo del cual somos hinchas, uno puede preguntarse: ¿cuáles son las chances de obtener una victoria?
Para intentar responder esta pregunta, los métodos y algoritmos de la ciencia de datos nos pueden ser de gran ayuda.

En este trabajo se aplicará la técnica de regresión logística para intentar, en primer lugar, identificar variables que puedan explicar el resultado de un partido de tenis y, en segundo lugar, utilizar esas mismas variables (u otras) para predecir el resultado del mismo.

No ahondaremos en la descripción detallada del modelo de regresión logística, ya que existe una gran cantidad de información acerca del mismo. Solo diremos que se trata de un modelo paramétrico, un caso particular de Modelo Lineal Generalizado (GLM), y que estos últimos vienen a generalizar a los modelos de regresión lineal tradicionales que todos conocemos.
En síntesis, es un modelo lineal adaptado para intentar resolver un problema de clasificación binaria, como puede ser el problema de modelar el resultado de un partido de tenis que tiene solo dos resultados posibles desde la óptica de nuestro jugador favorito: victoria o derrota.


## Selección de un Jugador

Para encarar el problema de predecir el resultado en un partido de tenis, parece intuitivo seleccionar un único jugador y buscar el mejor modelo para ese tenista.
Puede que algunas variables sean más o menos importantes para cada uno de los diferentes jugadores en el circuito, con lo cual esta forma de encarar el problema parece ser apropiada.

En este primer approach se modelará el resultado de un partido de tenis de Rafael Nadal, tenista con amplia trayectoria en el circuito y con un caudal de partidos que le otorga robustez a los análisis que se realizarán.


# Desarrollo

En las próximas secciones iremos desarrollando, paso a paso, la aplicación de modelos de regresión logística en nuestro problema de clasificación. Todo el trabajo ha sido realizado usando R como herramienta principal.


## Setup

Arrancamos con un setup del environment donde vamos a trabajar.


```{r setup}
#Cargo librerías de interés
pacman::p_load(pacman, tidyverse, rio, magrittr, lubridate,
               boot, caret, e1071, readr, correlation, see, ggraph,
               RColorBrewer, ggthemes, psych)
options(scipen = 999) #Elimino notación científica
```


Importamos la base de datos con la que trabajaremos. La misma fue confeccionada a partir de los registros históricos de partidos correspondientes al ATP Men's Tour, publicado por el sitio http://www.tennis-data.co.uk/, a quien agradecemos infinitamente por el aporte.


```{r data_import, warning=FALSE, message=FALSE}
#importo base desde repositorio en github
path <- "https://raw.githubusercontent.com/tomasroel/ProyectoKickRepo/main/Output/matches_nadal_ok.csv"
matches_nadal_ok <- read_csv(url(path))[,-1]

#separo las variables a utilizar
variables <- c("Location", "Series", "Court", "Surface", "Date",
               "Round", "BestOf", "RankNadal", "RankRival",
               "PartidosUlt6Meses", "PartidosUlt3Meses", "PartidosUltMes",
               "WRUlt6Meses", "WRUlt3Meses", "WRUltMes",
               "PartidosRivalUlt6Meses", "PartidosRivalUlt3Meses",
               "PartidosRivalUltMes", "WRRivalUlt6Meses", "WRRivalUlt3Meses",
               "WRRivalUltMes", "SetsGanadosUltPartido", "SetsPerdidosUltPartido",
               "ResultUltPartido", "RoundUltPartido", "H2HPartidos", "H2HGanados",
               "Result")
#Ajusto data types de variables
df_matches <- matches_nadal_ok %>% 
  select(all_of(variables)) %>% 
  mutate_at(vars(Location, Series, Court, Surface,
                 Round, BestOf, ResultUltPartido, RoundUltPartido, Result),
            as.factor)
glimpse(df_matches) #Vistazo a la base
```

Nuestra variable target será 'Resultado'. Esta variable puede tomar solo dos valores, "win" o "lose". El resto de las variables aportan información sobre el contexto en el cual se está jugando el partido (superficie, cantidad de sets a disputar, ronda, etc.) y también aportan información sobre la condición previa en que llega cada jugador al partido (ranking, cantidad de partidos jugados, porcentaje de partidos ganados, resultado del último partido, etc.).


## Data Wrangling

Ahora, con la base cargada, hacemos unos ajustes necesarios previos al análisis.

```{r data_wrangling}
#Elimino observaciones que no me sirven porque no tengo registro de los partidos anteriores
df_matches %>%
  select(Location, RankNadal,
         PartidosUlt6Meses, PartidosUlt3Meses, PartidosUltMes) %>% 
 print(n = 70)

#Elimino primeras 50 observaciones, a partir de ahí se nivela
df_matches <- df_matches[51:nrow(df_matches),]
```

## Plots

Vamos a echar un vistazo a los datos con los que vamos a trabajar mirando unos plots rápidos. La idea es ver cómo varía el porcentaje de victorias de Rafael Nadal en el circuito cuando segmentamos los partidos por alguna de las variables que tenemos disponibles.


```{r plots, fig.height=6, fig.width=12}
#Arranco mirando resultado según el rendimiento que tuvo en los últimos 6 meses.
df_matches %>% 
  ggplot(aes(x = PartidosUlt6Meses, y = WRUlt6Meses,
             color = Result)) + 
  geom_jitter(width = 1.5) +
  scale_color_brewer(palette = "Set1") + 
  labs(x = "Partidos Nadal Últimos 6 Meses",
       y = "Win Rate Nadal Últimos 6 Meses") + 
  theme_few()
#Miramos ahora la relación entre rankings y resultado del partido
df_matches %>% 
  ggplot(aes(x = RankNadal, y = RankRival,
             color = Result)) + 
  geom_jitter() + 
  coord_cartesian(ylim = c(0, 20),
                  xlim = c(0, 10)) +
  scale_x_continuous(breaks = c(1,3,5,7,9)) +
  scale_color_brewer(palette = "Set1") + 
  labs(x = "Ranking Nadal",
       y = "Ranking Rival") + 
  theme_few()
#Superficie y resultado
df_matches %>% 
  ggplot(aes(x = Surface, fill = Result)) + 
  geom_bar(position = "fill") +
  scale_fill_brewer(palette = "Set1") + 
  labs(x = "Surface") + 
  theme_few()
#Longitud del partido
df_matches %>% 
  ggplot(aes(x = BestOf, fill = Result)) + 
  geom_bar(position = "fill") + 
  facet_grid(.~Surface) +
  scale_fill_brewer(palette = "Set1") + 
  labs(x = "Best Of") + 
  theme_few()
#Ronda y superficie
df_matches %>% 
  ggplot(aes(x = Round, fill = Result)) + 
  geom_bar(position = "fill") + 
  facet_grid(.~Surface) + 
  scale_fill_brewer(palette = "Set1") + 
  labs(x = "Round",
       y = "Porcentaje de victorias") + 
  theme_few() +
  theme(axis.text.x = element_text(angle = 45,
                                   size = 6,
                                   vjust = 1,
                                   hjust = 1))
#Relación entre resultados de últimos 3 y 6 meses
df_matches %>% 
  ggplot(aes(x = PartidosUlt6Meses, y = PartidosUlt3Meses)) +
  geom_jitter() +
  scale_color_brewer(palette = "Set1") + 
  labs(x = "Partidos Nadal Últimos 6 Meses",
       y = "Partidos Nadal Últimos 3 Meses") + 
  theme_few()
#Relación entre partidos de últimos 3 y 6 meses
df_matches %>% 
  ggplot(aes(x = PartidosUlt6Meses, y = PartidosUltMes)) +
  geom_jitter() +
  scale_color_brewer(palette = "Set1") + 
  labs(x = "Partidos Nadal Últimos 6 Meses",
       y = "Partidos Nadal Último Mes") + 
  theme_few()
#Relación entre partidos del último mes 3 meses
df_matches %>% 
  ggplot(aes(x = PartidosUlt3Meses, y = PartidosUltMes)) +
  geom_jitter() +
  scale_color_brewer(palette = "Set1") + 
  labs(x = "Partidos Nadal Últimos 3 Meses",
       y = "Partidos Nadal Último Mes") + 
  theme_few()
```

Obtenemos algunas conclusiones de estos gráficos:

- Cuando Nadal llega con ritmo (cantidad de partidos) y con buen porcentaje de victorias (WR) parece ser más probable que obtenga una victoria en el partido.
- Si el rival forma parte del top 10, las chances de derrota son mayores.
- El clay (polvo de ladrillo) es sin dudas la superficie que mejor le sienta.
- A 5 sets parece haber una mejor performance en general de Nadal.
- En las primeras rondas del torneo tiende a tener un porcentaje de victorias mayor.

Con esto, claramente, no descubrimos nada nuevo. La intención ahora es utilizar estas conclusiones para modelar la probabilidad de victoria en un partido de Nadal, y en base a ello poder predecir el resultado del partido.

## Correlaciones entre Variables

Un punto sumamente importante a revisar previo al ajuste de modelos es el de las correlaciones parciales entre los variables que disponemos.
Con la base de datos disponible, calculamos las correlaciones entre cada una de las variables y vemos qué conclusiones podemos sacar.


```{r correlations, message=FALSE, warning=FALSE}
#Matriz de correlaciones en forma de lista y ordenada
correlation(df_matches[,c(3:4,6:28)] %>% 
              filter(!is.na(SetsPerdidosUltPartido) & !is.na(RoundUltPartido)),
            include_factors = TRUE,
            method = "auto") %>% 
  as_tibble() %>% 
  arrange(desc(r))
```
Las variables con una alta correlación (ya sea positiva o negativa) no deberían ser utilizadas de forma conjunta como predictoras en un modelo de regresión ya que afectan de forma negativa el resultado del mismo.

Analizando la tabla de correlaciones podemos sacar conclusiones que en principio pueden parecer triviales, como por ejemplo, que hay una alta correlación entre la variable 'Round' y la variable 'RoundUltPartido'. También podemos obtener otras conclusiones más importantes, como por ejemplo que existe una alta correlación positiva ente el win rate de los últimos 6 y 3 meses, tanto para los rivales como para Nadal. Lo mismo pasa entre el win rate de los últimos 3 meses y el del último mes.

A la hora de elegir combinaciones de predictoras tendremos entonces que prestar atención a estos resultados e intentar combinar variables con poca correlación, como pueden ser la variable win rate del último mes con la variable win rate de los últimos 6 meses.

## Tasas de Corte

Vamos a utilizar un modelo logístico para predecir un resultado de un partido de tenis de Nadal. Ahora bien, cuando miremos los resultados de clasificación del modelo, ¿qué tasa de aciertos consideraremos como "buena"?
Nadal, de por sí, gana la gran mayoría de partidos en los que participa, con lo cual una buena estrategia para "predecir" el resultado del partido parece ser decir que siempre va a ganar Nadal, sin tener en cuenta ninguna variable adicional.

Veamos cuál sería, estadísticamente, nuestra tasa de acierto si nos jugáramos siempre a que gana Nadal.

```{r tasas_corte}
#Probabilidad histórica de victoria Nadal
tasa_historica <- df_matches %>% 
  pull(Result) %>% 
  table() %>% 
  prop.table() 
tasa_historica
#Probabilidad a partir de 2019
tasa_2019 <- df_matches %>% 
  filter(Date > ymd("2019-01-01")) %>% 
  pull(Result) %>% 
  table() %>% 
  prop.table() 
tasa_2019
#Probabilidad 2020 en adelante
tasa_2020 <- df_matches %>% 
  filter(Date > ymd("2020-01-01")) %>% 
  pull(Result) %>% 
  table() %>% 
  prop.table() 
tasa_2020
#Probabilidad post cuarentena
tasa_postReceso <- df_matches %>% 
  filter(Date > ymd("2020-08-01")) %>% 
  pull(Result) %>% 
  table() %>% 
  prop.table()
tasa_postReceso
#Probabilidad 2021
tasa_post2021 <- df_matches %>% 
  filter(Date > ymd("2020-12-31")) %>% 
  pull(Result) %>% 
  table() %>% 
  prop.table() 
tasa_post2021
#En clay 2019 en adelante
tasa_clay <- df_matches %>% 
  filter(Date > ymd("2018-12-31") & 
           Surface == "Clay") %>% 
  pull(Result) %>% 
  table() %>% 
  prop.table() 
tasa_clay
```

Las tasas históricas de victoria de Rafael Nadal son las siguientes:

- Histórica: `r round(tasa_historica[2]*100,2)`%
- A partir de 2019: `r round(tasa_2019[2]*100,2)`%
- 2020 en adelante: `r round(tasa_2020[2]*100,2)`%
- Post receso COVID-19: `r round(tasa_postReceso[2]*100,2)`%
- 2021: `r round(tasa_post2021[2]*100,2)`%
- Clay a partir de 2019: `r round(tasa_clay[2]*100,2)`%

En base a estos números, podemos decir que un modelo predictivo, para que sea realmente útil, debería tener una tasa de acierto esperada superior al 90%.
Un modelo que acierta el resultado en menos del 85% de los partidos no representa ninguna mejora respecto a la "estrategia" de predicción consistente en decir que siempre gana Nadal.


## Model Train

Ahora sí, ya con una primera impresión de cómo se ven los datos y cómo podrían afectar las covariables al resultado del partido, comenzamos a ajustar los modelos.

Como primer paso, vamos a ajustar un modelo con todas las covariables disponibles como predictoras. La función de linkeo con la que trabajaremos es la función 'logit'.

### Estrategia de Entrenamiento-Testeo

Como estrategia de entrenamiento y testeo, entrenamos utilizando *m-repeated k-fold cross validation* para obtener una medida del error que no esté sesgada por los datos. Este entrenamiento se realizará solo con los partidos previos a abril 2020 (inicio de la pandemia COVID-19). Los partidos post receso por pandemia serán utilizados como base de testeo, donde se analizará de forma más precisa la performance predictiva del modelo.

### Modelo 0: prueba de covariables

En el primer modelo ajustado - modelo 0 - se utilizarán todos los features disponibles para modelar el resultado del partido. De este análisis se desprenderán indicios sobre cuáles covariables pueden tener una fuerte relación con el resultado del partido.


```{r prueba_covariables, warning=FALSE, message=FALSE, fig.height=6, fig.width=12}
#Separo partidos post receso. Sera mi base test
df_matches_train <- df_matches %>% 
  filter(Date < "2020-04-01")
df_matches_test <- df_matches %>% 
  filter(Date >= "2020-04-01")
#Defino el trainControl, aplicable solo a este modelo.
trainControlfit0 <- trainControl(method = "cv", number = 10)
#Modelo 0 - prueba de covariables. No uso todas las variables, algunas no nos interesan
glm.fit0 <- train(Result ~ Court + Surface + Round + BestOf + RankNadal +
                    RankRival + PartidosUlt6Meses + PartidosUlt3Meses +
                    PartidosUltMes +  WRUlt6Meses + WRUlt3Meses + WRUltMes +
                    PartidosRivalUlt6Meses + PartidosRivalUlt3Meses +
                    PartidosRivalUltMes + WRRivalUlt6Meses + WRRivalUlt3Meses +
                    WRRivalUltMes + SetsGanadosUltPartido +
                    SetsPerdidosUltPartido +ResultUltPartido + RoundUltPartido +
                    H2HPartidos + H2HGanados,
                  data = df_matches_train,
                  trControl = trainControlfit0,
                  method = "glm",
                  family = "binomial",
                  na.action = na.omit)
#Vemos el objeto que obtenemos
glm.fit0 
#Armamos un gráfico para ver cuales son las variables más significativas en términos de p-valor
glm.fit0 %>% 
  summary() %>% 
  coef() %>% 
  as_tibble() %>% 
  cbind(Variable = glm.fit0 %>% 
          summary() %>% 
          coef() %>% rownames(),.) %>% 
  mutate(`Pr(>|z|)` = round(`Pr(>|z|)`, 6)) %>% 
  ggplot(aes(x = reorder(Variable, `Pr(>|z|)`), y = `Pr(>|z|)`)) + 
  geom_bar(stat = "identity", fill = brewer.pal(n = 5, "Set1")[2]) + 
  labs(x = "",
       y = "P Value") +
  theme_few() +
  theme(axis.text.x = element_text(angle = 45,
                                   size = 10,
                                   vjust = 1,
                                   hjust = 1))
```

Mirando los p-value de los coeficientes del modelo podemos ver que hay algunas variables que tienen un impacto significativo en el resultado del partido. Éstas son:

- Round: la instancia en el torneo a la cual corresponde el partido.
- Partidos jugados en los últimos 6 meses.
- Partidos jugados en los últimos 3 meses.
- Partidos jugados en el último mes.
- Win Rate en los últimos 6 meses.
- Win Rate en los últimos 3 meses.
- Win Rate en el último mes.
- Partidos jugados por el rival en el último mes.
- Win Rate del rival en el último mes.
- Resultado del último partido.
- Ronda del último partido

Estas variables parecen tener una importante capacidad para explicar el resultado del partido.
Las variables más importantes parecen ser la cantidad de partidos jugados en el último mes y el porcentaje de victorias en éste. Éstas dos dan un indicio de cómo llega el jugador al partido, es decir si llega con ritmo y en racha.
Otra variable importante parece ser la ronda a la que corresponde el partido, sobre todo si se trata de la final. Allí el modelo identifica que Nadal tiene altas chances de ganar.
La cantidad de partidos jugados y el porcentaje de victorias del rival también parecen ser muy importantes, ya que indican en qué condiciones llega el rival al partido.

### Ajuste de Modelos

Ahora, ajustaremos una serie de modelos, buscando el de mejor performance predictiva. La selección de covariables a utilizar en cada ajuste estará basada en las conclusiones obtenidas del modelo 0.
Para determinar cuál es el mejor modelo, compararemos la métrica de error obtenida del entrenamiento vía cross validation. También utilizaremos el dataset de testeo para valuar performance en éste.
La tasa de corte para clasificar los partidos en "win" o "lose" será del 80%. Es decir, si la probabilidad de victoria predicha por el modelo para un partido es del 80% o más, ese partido será clasificado como "win". Si es menor, el resultado predicho será de "lose".

```{r model_train, warning=FALSE, message=FALSE}
#Armo un listado con todos los modelos que voy a ajustar y sus formulas
vars <- list(model1 = "Round + PartidosUlt6Meses + PartidosUlt3Meses + PartidosUltMes + WRUlt6Meses + WRUlt3Meses + WRUltMes + PartidosRivalUltMes + WRRivalUltMes + ResultUltPartido",
             model2 = "Surface + BestOf + RankNadal + RankRival + Round + PartidosUlt6Meses + PartidosUltMes + WRUlt6Meses + WRUltMes + PartidosRivalUltMes + WRRivalUltMes + ResultUltPartido",
             model3 = "Surface + BestOf + RankNadal + RankRival + Round + PartidosUlt3Meses + PartidosUltMes + WRUlt3Meses + WRUltMes + PartidosRivalUltMes + WRRivalUltMes + ResultUltPartido",
             model4 = "Surface + BestOf + RankNadal + RankRival + Round + PartidosUltMes + WRUltMes + PartidosRivalUltMes + WRRivalUltMes",
             model5 = "Surface + PartidosUltMes + WRUltMes + PartidosUlt6Meses + WRUlt6Meses + PartidosRivalUltMes + WRRivalUltMes + ResultUltPartido + RoundUltPartido",
             model6 = "RankNadal + RankRival + Round + PartidosUltMes + WRUltMes + PartidosRivalUltMes + WRRivalUltMes")
#Armo una tabla donde se almacenan los resultados de los ajustes
results <- tibble(modelo = paste("glm.fit", 1:6, sep = ""),
                  cv.accuracy = rep(0, 6),
                  accuracy.test = rep(0, 6),
                  FP.Ratio.test = rep(0, 6))
#Defino el train control. Sera repeated CV, con 10 particiones y 10 repeticiones
trainControl <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
#Seteo semilla para que los resultados sean reproducibles
set.seed(1200)
#Defino la tasa de corte para el testeo
r <- 0.8
for (i in (1:nrow(results))) {
  
  formula <- as.formula(paste("Result ~ ", paste(vars[i]), sep = ""))
  model.fit <- train(formula,
                  data = df_matches_train,
                  trControl = trainControl,
                  method = "glm",
                  family = "binomial",
                  na.action = na.omit)
  
  assign(paste("glm.fit", i, sep=""), model.fit)
  
  results$cv.accuracy[i] = model.fit$results$Accuracy
  
  probs <- predict(model.fit, type = "prob", newdata = df_matches_test)$Win
  pred <- rep("Lose", nrow(df_matches_test))
  pred[probs >= r] = "Win"
  conf.matrix <- table(pred, actual = df_matches_test$Result)
  
  results$accuracy.test[i] = 
    (conf.matrix[1,1] + conf.matrix[2,2])/nrow(df_matches_test)
  
  results$FP.Ratio.test[i] = 
    conf.matrix[2,1]/(conf.matrix[1,1] + conf.matrix[2,1])
  
  rm(formula, model.fit, probs, pred, conf.matrix)

}

results
```

Esta tabla resume, para cada modelo, la siguiente información:

- Accuracy (porcentaje de aciertos) obtenido vía cross-validation.
- Accuracy (porcentaje de aciertos) obtenido sobre la base de testo (post receso pandemia) con una tasa de corte del 80% (si la probabilidad predicha es superior 80%, se predice "win").
- False-Positive ratio test: indica el porcentaje de partidos perdidos por Nadal que el modelo predice como "ganados", utilizando la base de testeo post receso. Es decir, son los falsos positivos sobre el total de negativos.

El false-positive ratio es muy importante en este análisis ya que los partidos en los que Nadal sale derrotado son realmente pocos, con lo cual poder identificar esos pocos partidos donde Nadal no gana es algo de gran utilidad.

### Selección del Modelo

Basándonos exclusivamente en el error calculado por el método de cross-validation podemos concluir que todos los modelos tienen un rendimiento similar, y éste es en general muy bueno. Vamos a seleccionar el modelo número 3, que es el que tiene el mayor accuracy. Los modelos 2 y 3 tienen una composición de variables muy similar.

Veamos un resumen de este modelo:

```{r glm_selected}
#Resumen del modelo
summary(glm.fit3)
```

Se observa que hay variables que no son significativas, como por ejemplo el ranking de los jugadores y el win rate de los últimos 3 meses de Nadal (poseen un p-value alto).

Vamos a sacar esas variables y analizar otra vez el accuracy del modelo.

```{r tunning, message=FALSE, warning=FALSE}
#Nuevo ajuste eliminando variables con poco impacto en glm.fit3
glm.fit3.1 <- train(Result ~ Surface + BestOf + Round + 
                      PartidosUltMes +WRUltMes + PartidosRivalUltMes +
                      WRRivalUltMes + ResultUltPartido,
                    data = df_matches_train,
                    trControl = trainControl,
                    method = "glm",
                    family = "binomial",
                    na.action = na.omit)
glm.fit3.1
```

Vemos que con este nuevo ajuste mejoramos el accuracy con respecto al modelo `glm.fit3`, con lo cual este será nuestro modelo final.
Veamos cómo impactan las variables seleccionadas en la probabilidad de victoria de Nadal.

```{r glm.fit.3.1, fig.height=6, fig.width=12}
#Armamos un gráfico para ver cuales son las variables más significativas en términos de p-valor
tabl_glm3.1 <- glm.fit3.1 %>% 
  summary() %>% 
  coef() %>% 
  as_tibble() %>% 
  cbind(Variable = glm.fit3.1 %>% 
          summary() %>% 
          coef() %>% rownames(),.) %>% 
  mutate(Estimate = round(Estimate, 3),
         pos = Estimate >= 0)
#Gráfico
tabl_glm3.1 %>% 
  ggplot(aes(x = reorder(Variable, -abs(Estimate)), y = Estimate, fill = pos)) +
  geom_col(position = "identity") +
  geom_text(aes(label = Estimate, vjust = -sign(Estimate))) +
  labs(x = "",
       y = "Beta Estimado") +
  coord_cartesian(ylim = c(-30,30))+
  theme_few() +
  theme(axis.text.x = element_text(angle = 45,
                                   size = 10,
                                   vjust = 1,
                                   hjust = 1),
        legend.position = "none")
```

Se puede ver que las variables que tienen mayor impacto en la estimación de la probabilidad de victoria para cada partido son el win rate del rival en el último mes, el cual afecta negativamente la probabilidad de victoria, y el win rate de Nadal en el último mes, que afecta positivamente a la probabilidad de victoria.
Esto es lógico, ya que un mayor porcentaje de victorias de Nadal en el último mes significa que llega al partido con una buena performance en los partidos previos, por lo que sus chances de victoria se incrementan. Exactamente lo opuesto sucede cuando el rival llega con un alto porcentaje de victorias.

Otro caso interesante es lo que sucede con la cantidad de partidos jugados en el último mes, tanto para Nadal como para el rival. Esta variable tiene el efecto opuesto a la de variable win rate, y es un tanto polémico. El modelo parece penalizar la probabilidad de victoria cuando el tenista (aplica tanto Nadal como el rival) viene con muchos partidos jugados en el último mes. Intuitivamente, lo que el modelo parece estar captando es que si el jugador llega con muchos partidos en el mes su probabilidad de victoria decae debido al cansancio acumulado.

Otra conclusión bastante obvia que se desprende del análisis es que si el partido se disputa sobre cancha lenta la probabilidad de victoria de Nadal crece, lo mismo sucede si el partido es al mejor de 5 sets.

En lo que respecta a los resultados predictivos del modelo, el mismo tiene una tasa de clasificación estimada por CV de más del 95%. Ahora bien, para obtener los mejores resultados predictivos debemos determinar el umbral de clasificación óptimo, es decir la probabilidad a partir de la cual vamos a clasificar un partido como victoria o derrota.

## Umbral de Clasificación

Una vez seleccionado el que creemos es nuestro mejor modelo, queda seleccionar el umbral de clasificación que utilizaremos para clasificar a un partido como "win" o "lose".
Este umbral se determinará mirando la curva ROC. Esta curva compara, para cada umbral (entre 0 y 1), dos métricas que son importantes y que calcularemos sobre la base de testeo:

- True-Positive Ratio (TPR): es el cociente entre los verdaderos positivos y el total de positivos reales.
- False-Positive Ratio (FPR): cociente entre falsos positivos y negativos totales.

El umbral óptimo de clasificación será el que nos deje con un alto TPR y un bajo FPR.

```{r curva_ROC}
#Computo probabilidades utilizando el modelo seleccioado
probs <- predict(glm.fit3.1, type = "prob", newdata = df_matches_test)$Win
#Armo factores para curva ROC
ROC_curve <- tibble(
  Umbral = rep(0, 39),
  TN = rep(0, 39),
  FN = rep(0, 39),
  FP = rep(0, 39),
  TP = rep(0, 39))

for (j in 1:39){
  
  corte <- j/40
  pred <- rep("Lose", nrow(df_matches_test))
  pred[probs > corte] = "Win"
  
  ROC_curve[j,1] = corte
  ROC_curve[j,2] = table(pred, df_matches_test$Result)[1,1]
  ROC_curve[j,3] = table(pred, df_matches_test$Result)[1,2]
  ROC_curve[j,4] = table(pred, df_matches_test$Result)[2,1]
  ROC_curve[j,5] = table(pred, df_matches_test$Result)[2,2]
  
  rm(corte, pred)
  
}

ROC_curve %<>%
  mutate(TPR = TP/(TP+FN),
         FPR = FP/(FP+TN))
ROC_curve
```

Observando la evolución del TPR y el FPR, podemos concluir que un umbral de clasificación razonable y óptimo parece ser 0.925. Priorizamos bajar el FPR al mínimo ya que es de nuestro interés poder identificar aquellos partidos donde Nadal pierde, partidos que claramente son los menos.


# Resultados Finales

La matriz de confusión final, para la base de testeo post receso quedaría de la siguiente manera:

```{r matriz_confusion}
#computo matriz de confusion final para base de testeo
corte <- 0.925
pred <- rep("Lose", nrow(df_matches_test))
pred[probs > corte] = "Win"
table(pred, real = df_matches_test$Result)
```

Se observa que hay solo un partido donde Nadal no ganó que queda mal clasificado, partido en el que Nadal tenía una alta probabilidad de victoria y sin embargo perdió. Veamos de qué partido se trata.

```{r outlier}
#identifico partido perdido mal clasificado
cual <- which(pred != df_matches_test$Result)
df_matches_test[cual,] %>% filter(Result == "Lose")
```

El partido en cuestión corresponde a los cuartos de final del Masters 1000 de Roma, donde Rafael Nadal cayó ante Diego Schwartzman. Sin dudas se trató de una derrota inesperada, ya que la superficie y el ranking jugaban a favor de Nadal. El porcentaje de victorias de Schwartzman en los últimos 3 meses tampoco era demasiado bueno.
Sin dudas se trató de un resultado inesperado y, por supuesto, de un gran partido de Diego.

# Conclusión

Como conclusión final, podemos decir que el modelo de regresión logística funciona muy bien para predecir el resultado de un partido de Rafael Nadal. Sin dudas el fuerte de esta técnica es su capacidad explicativa, que permite no solo ver qué variables son las que muestran una fuerte influencia sobre el resultado, sino que además podemos ver en qué dirección afectan el mismo.

Como modelo predictivo el desempeño también es muy bueno, logrando una precisión de clasificación del 95%, precisión que fue estimada de una forma insesgada utilizando cross validation.

Sin dudas, lo más importante es la capacidad del modelo para detectar aquellos partidos en donde Nadal pierde, ya que es algo que rara vez sucede.


