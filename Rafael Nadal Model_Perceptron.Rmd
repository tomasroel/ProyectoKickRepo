---
title: "Rafael Nadal Model - Perceptron Algorithm"
output: html_notebook
author: "Tomás Roel"
---

En este breve documento se implementará el algoritmo del perceptron para intentar predecir el resultado de un partido de tenis donde uno de los tenistas sea Rafael Nadal.

El perceptron es uno de los algoritmos de machine learning mas antiguos. No revisaremos aca su trasfondo matematico sino que evaluaremos unicamente su capacidad de clasificacion en este problema.

Comenzamos haciendo un setup del environment.

##Setup


```{r setup}
pacman::p_load(pacman, tidyverse, rio, magrittr, lubridate, caret)


options(scipen = 999)
```

Importamos la data previamente trabajada. La misma consiste de una base de más de 1000 partidos jugados por Rafael Nadal, con su correspondiente resultado (gana/pierde) y con una serie de metricas (covariables) que representan el contexto en el cual se jugo el partido.

##Data Import

Importo la base de datos con los partidos, selecciono las variables de interes y elimino observaciones que por cuestiones relacionadas al problema no me sirven.


```{r data_import}
matches_nadal_ok <- import("Output/matches_nadal_ok.Rdata") %>% 
  as_tibble()

glimpse(matches_nadal_ok)

# SEPARO VARIABLES A UTILIZAR

variables <- c("Location", "Series", "Court", "Surface", "Date",
               "Round", "BestOf", "RankNadal", "RankRival",
               "PartidosUlt6Meses", "PartidosUlt3Meses", "PartidosUltMes",
               "WRUlt6Meses", "WRUlt3Meses", "WRUltMes",
               "PartidosRivalUlt6Meses", "PartidosRivalUlt3Meses",
               "PartidosRivalUltMes", "WRRivalUlt6Meses", "WRRivalUlt3Meses",
               "WRRivalUltMes", "SetsGanadosUltPartido", "SetsPerdidosUltPartido",
               "ResultUltPartido", "RoundUltPartido", "H2HPartidos", "H2HGanados",
               "Result")

df_matches <- matches_nadal_ok %>% 
  select(all_of(variables))

glimpse(df_matches)

df_matches %>%
  select(Location, RankNadal,
         PartidosUlt6Meses, PartidosUlt3Meses, PartidosUltMes) %>% 
 print(n = 70)

#Elimino primeras 50 observaciones, a partir de ahi se nivela
#No tengo historia previa a esas 50 observaciones

df_matches <- df_matches[51:nrow(df_matches),]

```


##Tasas de Corte

Antes de arrancar con el model train, defino cuales seria un ratio de buena clasificacion aceptable para mi problema.

```{r tasas_corte}

# COMPUTO LAS TASAS DE CORTE ###################################

# Probabilidad histórica de victoria Nadal =====================

df_matches %>% 
  pull(Result) %>% 
  table() %>% 
  prop.table() # La probabilidad histórica es 83,9%.

#Si mi prediccion es que siemopre gana, acierto el 83% de las veces.

# Probabilidad ultimos 2 años ==================================

df_matches %>% 
  filter(Date > ymd("2019-01-01")) %>% 
  pull(Result) %>% 
  table() %>% 
  prop.table() #84,3% de las veces ganó

#Probabilidad 2020 en adelante =================================

df_matches %>% 
  filter(Date > ymd("2020-01-01")) %>% 
  pull(Result) %>% 
  table() %>% 
  prop.table() #81,8% de las veces ganó

#Probabilidad post cuarentena ==================================

df_matches %>% 
  filter(Date > ymd("2020-08-01")) %>% 
  pull(Result) %>% 
  table() %>% 
  prop.table() #78,26% de las veces ganó.

#Probabilidad 2021 =============================================

df_matches %>% 
  filter(Date > ymd("2020-12-31")) %>% 
  pull(Result) %>% 
  table() %>% 
  prop.table() #80% pero con pocos partidos jugados.

# En definitiva, si yo digo que gana nadal siempre
# voy a acertar un 80%. Necesito un modelo que supere claramente ese nro
# O sea un modelo de + de 90% de acierto.

#En clay 2019 en adelante

df_matches %>% 
  filter(Date > ymd("2018-12-31") & 
           Surface == "Clay") %>% 
  pull(Result) %>% 
  table() %>% 
  prop.table() #90% en clay

```


Para ser considerado como un buen modelo, los ajustes que realice deben obtener como resultado una tasa de buena clasificacion superior al 90% sobre una base de testeo. Modelos con un accuracy inferior no deberian ser tenidos en cuenta ya que la estrategia de predecir que Nadal "gana siempre" tendra un resultado similar.


##El Perceptron

En el siguiente apartado vamos a escribir el algoritmo del perceptron que luego entrenaremos con los datos.
El codigo fue extaido del siguiente post: https://rpubs.com/FaiHas/197581. El mismo fue escrito por Faiyaz Hasan.
Solo haremos unas pequeñas modificaciones a su aporte.


```{r perceptron}
# write function that takes in the data frame, learning rate - lambda, and number of epochs - n.iter and updates the weight factor. At this stage, I am only concerned with the final weight and the number of epochs required for the weight to converge

perceptron <- function(x, y, lambda, niter) {
        
        # initialize weight vector
        weight <- rep(0, dim(x)[2] + 1)
        errors <- rep(0, niter)
        
        
        # loop over number of epochs niter
        for (jj in 1:niter) {
                
                # loop through training data set
                for (ii in 1:length(y)) {
                        
                        # Predict binary label using Heaviside activation 
                        # function
                        z <- sum(weight[2:length(weight)] * 
                                         as.numeric(x[ii, ])) + weight[1]
                        if(z < 0) {
                                ypred <- -1
                        } else {
                                ypred <- 1
                        }
                        
                        # Change weight - the formula doesn't do anything 
                        # if the predicted value is correct
                        weightdiff <- lambda * (y[ii] - ypred) * 
                                c(1, as.numeric(x[ii, ]))
                        weight <- weight + weightdiff
                        
                        # Update error function
                        if ((y[ii] - ypred) != 0.0) {
                                errors[jj] <- errors[jj] + 1
                        }
                        
                }
        }
        
        # weight to decide between the two species 
        print(weight)
        return(errors)
}

```


##Model Train

Una vez definido el algoritmo, vamos a entrenarlo con la data de partidos que tenemos disponible.


```{r model_train}
#En primer lugar, seleccionaremos las variables que formaran parte del modelo

perc_matches <- df_matches[,-c(1,2)]

#Transformamos Result y ResultUltPartido en variables numericas

perc_matches %<>% 
  mutate(ResultUltPartido = recode(ResultUltPartido, "Win" = 1, "Lose" = 0),
         Result = recode(Result, "Win" = 1, "Lose" = 0))

glimpse(perc_matches)
perc_matches <- perc_matches[,-3] 
perc_matches %<>% 
  mutate(RoundUltPartido = as.factor(RoundUltPartido))

#Ahora transformo todas las variables categoricas en numericas

dummy <- dummyVars("~.", data = perc_matches)
data_perc <- as_tibble(predict(dummy, newdata = perc_matches))

data_perc <- as.matrix(data_perc)

prepoc1 <- preProcess(data_perc[,c(17:32,42:43)], method = c("range"))
norm1 <- predict(prepoc1, data_perc[,c(17:32,42:43)])
summary(norm1)

data_perc <- cbind(norm1, data_perc[,-c(17:32,42:43)])
summary(data_perc)

#Elimino los 15 registros que tienen NA values

data_perc <- data_perc[-which(is.na(data_perc[,16])),]

summary(data_perc)

#Separo data en train y test

data_perc_train <- data_perc[1:(nrow(data_perc)-50), 1:43]
data_perc_test <- data_perc[(nrow(data_perc)-49):nrow(data_perc), 1:43]
target_perc_train <- data_perc[1:(nrow(data_perc)-50), 44]
target_perc_test <- data_perc[(nrow(data_perc)-49):nrow(data_perc), 44]


#Ahora con los valores separados, hago el train
#previamente defino los valores de lambda y niter

lam <- 0.1
niter <- 100

perceptron(data_perc_train, target_perc_train, lam, niter)


```

